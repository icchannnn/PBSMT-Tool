import nltk
from nltk import pos_tag
import subprocess

# nltk.download('averaged_perceptron_tagger')
# nltk.download('punkt')
# nltk.data.path.append('/mnt/c/Users/itcha/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0/LocalCache/Roaming/nltk_data')

class PhraseBasedSMT:
    def __init__(self, parallel_corpus_path, monolingual_corpus_path):
        self.parallel_corpus_path = parallel_corpus_path
        self.monolingual_corpus_path = monolingual_corpus_path
        self.parallel_corpus = self.read_corpus(parallel_corpus_path)
        self.monolingual_corpus = self.read_corpus(monolingual_corpus_path)
        self.source_tokenized = [nltk.word_tokenize(sentence.lower()) for sentence in self.parallel_corpus]
        self.target_tokenized = [nltk.word_tokenize(sentence.lower()) for sentence in self.parallel_corpus]  # Adjust as needed
        self.monolingual_tokenized = [nltk.word_tokenize(sent.lower()) for sent in self.monolingual_corpus]

        # Save the tokenized monolingual data to a text file
        self.save_tokenized_to_file()

        # Initialize components
        self.source_pos_tags = None
        self.target_pos_tags = None
        self.source_word_alignment = None
        self.phrase_table = None

    def read_corpus(self, file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            corpus = [line.strip() for line in f]
        return corpus

    def save_tokenized_to_file(self):
        # Join the tokenized sentences into a single string
        tokenized_text = ' '.join([' '.join(sent) for sent in self.monolingual_tokenized])

        # Write the tokenized text to a file
        with open('/mnt/c/smt/pbsmt/monolingual_tokenized.txt', 'w', encoding='utf-8') as file:
            file.write(tokenized_text)

    def train(self):
        # Train the language model
        self.train_language_model()

    def train_language_model(self):
        # Train a language model using an external tool (e.g., KenLM)
        subprocess.call(f"/mnt/c/smt/pbsmt/ubuntu-16.04/bin/lmplz -o 3 < /mnt/c/smt/pbsmt/monolingual_tokenized.txt > /mnt/c/smt/pbsmt/language_model.arpa", shell=True)

        subprocess.call(f"/mnt/c/smt/pbsmt/ubuntu-16.04/bin/build_binary /mnt/c/smt/pbsmt/language_model.arpa /mnt/c/smt/pbsmt/language_eng.bin", shell=True)


# Example usage:
parallel_corpus_path = "/mnt/c/smt/pbsmt/parallel_corpus.txt"
monolingual_corpus_path = "/mnt/c/smt/pbsmt/monolingual_corpus.txt"

smt_model = PhraseBasedSMT(parallel_corpus_path, monolingual_corpus_path)
smt_model.train()
